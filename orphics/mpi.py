from __future__ import print_function
import numpy as np
import os,sys,time

try:
    disable_mpi_env = os.environ['DISABLE_MPI']
    disable_mpi = True if disable_mpi_env.lower().strip() == "true" else False
except:
    disable_mpi = False


# From Sigurd's enlib.mpi:
# Uncaught exceptions don't cause mpi to abort. This can lead to thousands of
# wasted CPU hours
def cleanup(type, value, traceback):
	sys.__excepthook__(type, value, traceback)
	MPI.COMM_WORLD.Abort(1)
sys.excepthook = cleanup

class fakeMpiComm:
    """
    A Simple Fake MPI implementation
    """
    def __init__(self):
        pass
    def Get_rank(self):
        return 0
    def Get_size(self):
        return 1
    def Barrier(self):
        pass
    def Abort(self,dummy):
        pass




try:
    if disable_mpi: raise
    from mpi4py import MPI
except:

    if not(disable_mpi): print("WARNING: mpi4py could not be loaded. Falling back to fake MPI. This means that if you submitted multiple processes, they will all be assigned the same rank of 0, and they are potentially doing the same thing.")
    
    class template:
        pass

    MPI = template()
    MPI.COMM_WORLD = fakeMpiComm()


def mpi_distribute(num_tasks,avail_cores):

    assert avail_cores<=num_tasks
    min_each, rem = divmod(num_tasks,avail_cores)
    num_each = np.array([min_each]*avail_cores) # first distribute equally
    if rem>0: num_each[-rem:] += 1  # add the remainder to the last set of cores (so that rank 0 never gets extra jobs)

    task_range = list(range(num_tasks)) # the full range of tasks
    cumul = np.cumsum(num_each).tolist() # the end indices for each task
    task_dist = [task_range[x:y] for x,y in zip([0]+cumul[:-1],cumul)] # a list containing the tasks for each core
    return num_each,task_dist
    



class MPIDict(object):

    def __init__(self,init_dict,comm):
        self.rank = comm.Get_rank()
        self.numcores = comm.Get_size()
        self.comm = comm
        if self.rank==0:
            self.d = init_dict
        else:
            self.s = {}
        
    def update(self,key,value):
        if self.rank==0:
            self.d[key] = value
        else:
            self.s[key] = value
    def collect(self):
        if self.rank!=0:
            self.comm.send(self.s,dest=0,tag=self.rank)
            return None
        else:
            for i in range(1,self.numcores):
                s = self.comm.recv(source=i,tag=i)
                for key in s.keys():
                    assert key not in self.d.keys()
                    self.d[key] = s[key].copy()
            return self.d
            
    


    

        

### SCINET JOBMAKER
"""
Not technically MPI and kind of legacy.
"""

class jobMaker:

    '''
    Use this to send jobs to SciNet GPC in batches of numCores
    '''
    

    def __init__(self,projectName,walltime,commandPreFix="",numCores=8,queue='debug',jobRoot=None):
        

        self.numCores = numCores
        self.queue = queue
        self._headerText = "#!/bin/bash\n"+\
            "# MOAB/Torque submission script for multiple serial jobs on\n"+\
            "# SciNet GPC automatically generated by gpcInterface.jobMaker().\n"+\
            "#\n"+\
            "#PBS -l nodes=1:ppn=8,walltime="
        self._headerText2 = "\n#PBS -N "
        self._headerText3 = "\n#PBS -q " 
        self._headerText4 = "\n# DIRECTORY TO RUN - $PBS_O_WORKDIR is directory job was submitted from\n"+\
            "cd $PBS_O_WORKDIR\n"
        
        self.name = projectName
        self.walltime = walltime

        self._header = self._headerText + self.walltime + self._headerText2 + self.name + self._headerText3 + self.queue + self._headerText4

        self.jobScript = self._header

        if commandPreFix!="":
            self.prefix = commandPreFix+"; "
        else:
            self.prefix = commandPreFix

        self.scripts = []
        self._jobCount = 0
        self.submittedJobIDs = []

        if jobRoot==None:
            self._jobRoot = "jobs/"
        else:
            self._jobRoot = jobRoot
        self._jobLog = open(jobRoot+"jobs.log",'a')
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
        self._jobLog.write("\nStarted jobMaker object named =="+self.name+"== at "+timestamp)

    def addJob(self,command):

        self._jobCount+=1
        self.jobScript = self.jobScript+"\n("+self.prefix+command+") &"

        if self._jobCount%self.numCores==0:
            self.scripts.append(self.jobScript + "\n\nwait\n")
            self.jobScript = self._header

    def submit(self):
        import re

        if self._jobCount%self.numCores!=0:
            self.scripts.append(self.jobScript + "\n\nwait\n")
            self.jobScript = self._header

        self.jobScript = self._header

        j=0
        for script in self.scripts:
            j+=1
            filename = self._jobRoot+self.name+str(time.time())+str(j)+".sh"
            with open(filename,'w') as tempFile:
                tempFile.write(script)

            # print script
            # continue
            #sys.exit()    
            ##suboutput = os.popen('python labs/testthis.py').read()
            suboutput = os.popen('qsub '+filename).read()
            print (suboutput)
            jobid = int(re.findall('\d+', suboutput)[0])
            self.submittedJobIDs.append(jobid)

            timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
            self._jobLog.write("\nOutput from script submitted at  "+timestamp+":\n"+suboutput)

            


        print (self._jobCount, "job(s) submitted in", j, "script(s).")
        
        self.scripts = []
        self._jobCount = 0



    
    def __del__(self):
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
        self._jobLog.write("\nClosed jobMaker object named =="+self.name+"== at "+timestamp)
        self._jobLog.close()
